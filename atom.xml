<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://shxiangyan.github.io/</id>
    <title>Shxiangyan&apos;s Home</title>
    <updated>2020-04-15T04:01:14.869Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://shxiangyan.github.io/"/>
    <link rel="self" href="https://shxiangyan.github.io/atom.xml"/>
    <subtitle>shxiangyan@gmail.com</subtitle>
    <logo>https://shxiangyan.github.io/images/avatar.png</logo>
    <icon>https://shxiangyan.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Shxiangyan&apos;s Home</rights>
    <entry>
        <title type="html"><![CDATA[GAN]]></title>
        <id>https://shxiangyan.github.io/post/gan/</id>
        <link href="https://shxiangyan.github.io/post/gan/">
        </link>
        <updated>2020-04-15T03:59:55.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-gangenerative-adversarial-network">1. GAN(Generative Adversarial Network)</h2>
<p>一个生成对抗网络包含两个均由多层神经网络构成的模型:(Generaive Model &amp; Discriminative Model).G 产生仿真数据分布,D 判别数据是仿真还是真实的.GAN的训练过程是使G产生的仿真数据尽可能逼近真实数据,同时又使D尽量好地区分仿真数据和真实数据,目标是使G产生的数据足以以真乱假,是D判别真假的概率均为0.5.</p>
<pre><code class="language-python">#+BEGIN_SRC python output:results
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

# torch.manual_seed(1)    # reproducible
# np.random.seed(1)

# Hyper Parameters
BATCH_SIZE = 64
LR_G = 0.0001           # learning rate for generator
LR_D = 0.0001           # learning rate for discriminator
N_IDEAS = 5             # think of this as number of ideas for generating an art work (Generator)
ART_COMPONENTS = 15     # it could be total point G can draw in the canvas
PAINT_POINTS = np.vstack([np.linspace(-1, 1, ART_COMPONENTS) for _ in range(BATCH_SIZE)])

# show our beautiful painting range
# plt.plot(PAINT_POINTS[0], 2 * np.power(PAINT_POINTS[0], 2) + 1, c='#74BCFF', lw=3, label='upper bound')
# plt.plot(PAINT_POINTS[0], 1 * np.power(PAINT_POINTS[0], 2) + 0, c='#FF9359', lw=3, label='lower bound')
# plt.legend(loc='upper right')
# plt.show()


def artist_works():     # painting from the famous artist (real target)
    a = np.random.uniform(1, 2, size=BATCH_SIZE)[:, np.newaxis]
    paintings = a * np.power(PAINT_POINTS, 2) + (a-1)
    paintings = torch.from_numpy(paintings).float()
    return paintings

G = nn.Sequential(                      # Generator
    nn.Linear(N_IDEAS, 128),            # random ideas (could from normal distribution)
    nn.ReLU(),
    nn.Linear(128, ART_COMPONENTS),     # making a painting from these random ideas
)

D = nn.Sequential(                      # Discriminator
    nn.Linear(ART_COMPONENTS, 128),     # receive art work either from the famous artist or a newbie like G
    nn.ReLU(),
    nn.Linear(128, 1),
    nn.Sigmoid(),                       # tell the probability that the art work is made by artist
)

opt_D = torch.optim.Adam(D.parameters(), lr=LR_D)
opt_G = torch.optim.Adam(G.parameters(), lr=LR_G)

plt.ion()   # something about continuous plotting

for step in range(10000):
    artist_paintings = artist_works()           # real painting from artist
    G_ideas = torch.randn(BATCH_SIZE, N_IDEAS)  # random ideas
    G_paintings = G(G_ideas)                    # fake painting from G (random ideas)

    prob_artist0 = D(artist_paintings)          # D try to increase this prob
    prob_artist1 = D(G_paintings)               # D try to reduce this prob

    D_loss = - torch.mean(torch.log(prob_artist0) + torch.log(1. - prob_artist1))
    G_loss = torch.mean(torch.log(1. - prob_artist1))

    opt_D.zero_grad()
    D_loss.backward(retain_graph=True)      # reusing computational graph
    opt_D.step()

    opt_G.zero_grad()
    G_loss.backward()
    opt_G.step()

    if step % 50 == 0:  # plotting
        plt.cla()
        plt.plot(PAINT_POINTS[0], G_paintings.data.numpy()[0], c='#4AD631', lw=3, label='Generated painting',)
        plt.plot(PAINT_POINTS[0], 2 * np.power(PAINT_POINTS[0], 2) + 1, c='#74BCFF', lw=3, label='upper bound')
        plt.plot(PAINT_POINTS[0], 1 * np.power(PAINT_POINTS[0], 2) + 0, c='#FF9359', lw=3, label='lower bound')
        plt.text(-.5, 2.3, 'D accuracy=%.2f (0.5 for D to converge)' % prob_artist0.data.numpy().mean(), fontdict={'size': 13})
        plt.text(-.5, 2, 'D score= %.2f (-1.38 for G to converge)' % -D_loss.data.numpy(), fontdict={'size': 13})
        plt.ylim((0, 3));plt.legend(loc='upper right', fontsize=10);plt.draw();plt.pause(0.01)

plt.ioff()
plt.show()
</code></pre>
<h2 id="2-cycle-gan">2. Cycle GAN</h2>
<p>CycleGAN的创新点在于能够在源域和目标域之间，无须建立训练数据间一对一的映射，就可实现这种迁移.</p>
<figure data-type="image" tabindex="1"><img src="https://pic1.zhimg.com/80/v2-a0b491f3983739c6aadb892254d34b00_720w.jpg" alt="" loading="lazy"></figure>
<p>想要做到这点，有两个比较重要的点，第一个就是双判别器。如下图所示，两个分布X,Y，生成器G，F分别是X到Y和Y到X的映射，两个判别器Dx,Dy可以对转换后的图片进行判别。第二个点就是cycle-consistency loss，用数据集中其他的图来检验生成器，这是防止G和F过拟合，比如想把一个小狗照片转化成梵高风格，如果没有cycle-consistency loss，生成器可能会生成一张梵高真实画作来骗过Dx，而无视输入的小狗。</p>
<figure data-type="image" tabindex="2"><img src="https://pic3.zhimg.com/80/v2-dde91dabff84db3086a4c8b761e46eb6_720w.jpg" alt="" loading="lazy"></figure>
<p>Cycle Consistency 损失</p>
<pre><code class="language-python">D_A_loss_1 = tf.reduce_mean(tf.squared_difference(dec_A,1))
D_B_loss_1 = tf.reduce_mean(tf.squared_difference(dec_B,1))

D_A_loss_2 = tf.reduce_mean(tf.square(dec_gen_A))
D_B_loss_2 = tf.reduce_mean(tf.square(dec_gen_B))


D_A_loss = (D_A_loss_1 + D_A_loss_2)/2 #前向指导
D_B_loss = (D_B_loss_1 + D_B_loss_2)/2


g_loss_B_1 = tf.reduce_mean(tf.squared_difference(dec_gen_A,1))#反向生成
g_loss_A_1 = tf.reduce_mean(tf.squared_difference(dec_gen_A,1))


cyc_loss = tf.reduce_mean(tf.abs(input_A-cyc_A)) + tf.reduce_mean(tf.abs(input_B-cyc_B))
g_loss_A = g_loss_A_1 + 10*cyc_loss
g_loss_B = g_loss_B_1 + 10*cyc_loss
</code></pre>
<h2 id="3-接下来的工作">3. 接下来的工作</h2>
<p>利用GAN预训练模型制作姿态估计数据集,自动生成模型.</p>
<p>对OpenCV考察调研</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[服务器配置]]></title>
        <id>https://shxiangyan.github.io/post/fu-wu-qi-pei-zhi/</id>
        <link href="https://shxiangyan.github.io/post/fu-wu-qi-pei-zhi/">
        </link>
        <updated>2020-04-10T13:20:02.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1显卡">1.显卡</h2>
<table>
<thead>
<tr>
<th style="text-align:center">型号(NVIDIA GetForce)</th>
<th style="text-align:center">显存</th>
<th style="text-align:center">精度</th>
<th style="text-align:center">价格(元)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">2080Ti</td>
<td style="text-align:center">11</td>
<td style="text-align:center">13.4</td>
<td style="text-align:center">9999</td>
</tr>
<tr>
<td style="text-align:center">2080</td>
<td style="text-align:center">8</td>
<td style="text-align:center">10.1</td>
<td style="text-align:center">5999</td>
</tr>
<tr>
<td style="text-align:center">2070</td>
<td style="text-align:center">8</td>
<td style="text-align:center">7.4</td>
<td style="text-align:center">4599</td>
</tr>
<tr>
<td style="text-align:center">Titan V</td>
<td style="text-align:center">12</td>
<td style="text-align:center">14.8</td>
<td style="text-align:center">24099</td>
</tr>
<tr>
<td style="text-align:center">Titan RTX</td>
<td style="text-align:center">24</td>
<td style="text-align:center">12.4</td>
<td style="text-align:center">20199</td>
</tr>
<tr>
<td style="text-align:center">TITAN Xp</td>
<td style="text-align:center">12</td>
<td style="text-align:center">12</td>
<td style="text-align:center">9699</td>
</tr>
<tr>
<td style="text-align:center">1080Ti</td>
<td style="text-align:center">11</td>
<td style="text-align:center">11.5</td>
<td style="text-align:center">8699</td>
</tr>
<tr>
<td style="text-align:center">1080</td>
<td style="text-align:center">8</td>
<td style="text-align:center">9</td>
<td style="text-align:center">4899</td>
</tr>
<tr>
<td style="text-align:center">1070Ti</td>
<td style="text-align:center">8</td>
<td style="text-align:center">8.1</td>
<td style="text-align:center">3999</td>
</tr>
<tr>
<td style="text-align:center">1070</td>
<td style="text-align:center">8</td>
<td style="text-align:center">6.5</td>
<td style="text-align:center">2899</td>
</tr>
<tr>
<td style="text-align:center">1060</td>
<td style="text-align:center">6</td>
<td style="text-align:center">4.3</td>
<td style="text-align:center">2199</td>
</tr>
</tbody>
</table>
<h2 id="2配置推荐">2.配置推荐</h2>
<table>
<thead>
<tr>
<th style="text-align:center">硬件</th>
<th style="text-align:center">型号</th>
<th style="text-align:center">数量</th>
<th style="text-align:center">共金额(元)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CPU</td>
<td style="text-align:center">英特尔i7-9700KF 8核16线程</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2799</td>
</tr>
<tr>
<td style="text-align:center">GPU</td>
<td style="text-align:center">2080Ti</td>
<td style="text-align:center">2</td>
<td style="text-align:center">19998</td>
</tr>
<tr>
<td style="text-align:center">主板</td>
<td style="text-align:center">华硕PRIME Z390-P</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1249</td>
</tr>
<tr>
<td style="text-align:center">内存</td>
<td style="text-align:center">海盗船复仇者LPX 16GB DDR4 3000（CMK16GX4M1B3000C15）</td>
<td style="text-align:center">4</td>
<td style="text-align:center">2076</td>
</tr>
<tr>
<td style="text-align:center">电源</td>
<td style="text-align:center">海盗船RM1000x</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1299</td>
</tr>
<tr>
<td style="text-align:center">固态</td>
<td style="text-align:center">Intel 760P M.2 2280（512GB）</td>
<td style="text-align:center">1</td>
<td style="text-align:center">749</td>
</tr>
<tr>
<td style="text-align:center">机械硬盘</td>
<td style="text-align:center">希捷BarraCuda Pro 4TB 7200转 128MB</td>
<td style="text-align:center">1</td>
<td style="text-align:center">649</td>
</tr>
<tr>
<td style="text-align:center">散热</td>
<td style="text-align:center">海盗船H150i PRO RGB</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1379</td>
</tr>
<tr>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">总金</td>
<td style="text-align:center">30948</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bandicam]]></title>
        <id>https://shxiangyan.github.io/post/bandicam/</id>
        <link href="https://shxiangyan.github.io/post/bandicam/">
        </link>
        <updated>2020-04-01T12:20:11.000Z</updated>
        <summary type="html"><![CDATA[<p>👉老师您要的录屏软件<br>
👉👇</p>
]]></summary>
        <content type="html"><![CDATA[<p>👉老师您要的录屏软件<br>
👉👇</p>
<!-- more -->
<h2 id="1双击bdcamsetupexe">1.双击bdcamsetup.exe</h2>
<h2 id="2点击下一步">2.点击下一步</h2>
<h2 id="3可以看到现在是未注册版">3.可以看到现在是未注册版</h2>
<h2 id="4再次打开之前解压的文件夹以管理员身份运行注册机">4.再次打开之前解压的文件夹，以管理员身份运行注册机</h2>
<h2 id="5在此随意输入一个邮箱即可">5.在此随意输入一个邮箱即可</h2>
<h2 id="6输入完毕点击-register-application">6.输入完毕点击 Register application！</h2>
<h2 id="7重启软件就会发现已经注册成功了">7.重启软件就会发现已经注册成功了</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[华为开发者会议]]></title>
        <id>https://shxiangyan.github.io/post/huawei/</id>
        <link href="https://shxiangyan.github.io/post/huawei/">
        </link>
        <updated>2020-03-31T04:06:44.000Z</updated>
        <summary type="html"><![CDATA[<p>👉<br>
👇</p>
]]></summary>
        <content type="html"><![CDATA[<p>👉<br>
👇</p>
<!-- more -->
<h1 id="1三大挑战">1.三大挑战</h1>
<h2 id="11数据">1.1数据</h2>
<p>如何海量数据挖掘有效信息?</p>
<h3 id="111-利用生成数据训练模型">1.1.1 利用生成数据训练模型</h3>
<p>为了解决数据标注瓶颈的关键技术.生成数据主要应用于智慧城市,智能驾驶.</p>
<ol>
<li>
<p>自动数据扩充</p>
</li>
<li>
<p>利用GAN模型来生成更多的数据</p>
</li>
<li>
<p>利用计算机图形学技术生成虚拟数据</p>
</li>
</ol>
<p>问题:单一的数据硬标签让数据自动扩充以后的图像不能完美的识别.</p>
<p>解决方法:知识蒸馏与数据扩充相结合:通过预训练模型对数据扩增的图片产生软标签,用软标签指导模型训练.</p>
<h3 id="112-对齐不同模态的数据">1.1.2 对齐不同模态的数据</h3>
<p>主要应用于,智能驾驶,智能多媒体</p>
<p>挑战:</p>
<ul>
<li>多模态信息表示</li>
<li>模态联合映射</li>
<li>模态对齐</li>
<li>模态融合</li>
<li>多模态协同融合</li>
</ul>
<p>根据文本\图像信息以及用户的数据建立多模态的查询语句.</p>
<h2 id="12-模型">1.2 模型</h2>
<h3 id="121-设计">1.2.1 设计</h3>
<p>用自动网络搜索代替手工网络设计.</p>
<p>挑战:</p>
<ul>
<li>搜索空间(人工经验来定义)</li>
<li>搜索算子(人工设计)</li>
<li>迁移性差</li>
</ul>
<p>PC-DARTS:局部连接的思路,解决网络冗余问题边正则化思想,解决局部连接带来的不稳定性.</p>
<h3 id="122-加速">1.2.2 加速</h3>
<p>挑战:</p>
<ul>
<li>云测大模型无法适配段侧的有限算力</li>
</ul>
<p>加法网络:新型算子加速卷积网络.使用曼哈顿距离取代欧式,卷积无需乘法计算,使用8比特整数计算,对硬件更加友好,功耗更低.公式如下:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo>(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo>)</mo><mo>=</mo><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi><mo>+</mo><mi mathvariant="normal">∣</mi><msub><mi>y</mi><mn>1</mn></msub><mo>−</mo><msub><mi>y</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">d(i,j)=|x_1-x_2|+|y_1-y_2|
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">d</span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span></span></p>
<h2 id="13-知识">1.3 知识</h2>
<h3 id="131-定义视觉与训练模型">1.3.1 定义视觉与训练模型</h3>
<p>挑战:</p>
<ul>
<li>监督学习需要海量的样本,数据拟合无法泛华到不同的数据.</li>
<li>强化学习需要海量的xx缺少可重复性,可复用性,鲁棒性.</li>
<li>自监督学习缺乏有效的预训练任务</li>
</ul>
<p>拼图任务改进自监督模型,使网络能够处理任意拼图布局从而更好地学习空间上下文提供的语义信息.</p>
<h3 id="132-通过虚拟环境更精确的学习知识">1.3.2 通过虚拟环境更精确的学习知识</h3>
<h1 id="2-mindspore计算框架开源">2 MindSpore计算框架开源</h1>
<ul>
<li>混合并行</li>
<li>云\边\端合一</li>
<li>兼顾学术工业</li>
<li>自动微分,并行计算,调优</li>
</ul>
<h1 id="3-modelarts-pro">3 ModelArts Pro</h1>
<p>从计算到认知的过程</p>
<p>生成API简单调用.</p>
<h1 id="4-hilens">4 HiLens</h1>
<p>端云协同多模态AI应用开发套件.</p>
<h1 id="5-atlas">5 Atlas</h1>
<p>检测工具.</p>
<p>分布式云计算:</p>
<ul>
<li>计算瓶颈</li>
<li>I/O瓶颈</li>
<li>内存瓶颈</li>
</ul>
<h1 id="名词">名词</h1>
<p>AA  自动数据扩增,对数据集的全局优化,容易带来图片语义的混淆.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[第五周]]></title>
        <id>https://shxiangyan.github.io/post/di-wu-zhou/</id>
        <link href="https://shxiangyan.github.io/post/di-wu-zhou/">
        </link>
        <updated>2020-03-30T09:19:32.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1取得成果">1.取得成果</h1>
<figure data-type="image" tabindex="1"><img src="https://shxiangyan.github.io//post-images/1585560783488.png" alt="" loading="lazy"></figure>
<p>构建了数据分别在，VGG16、InceptionV3、ResNeXt50，Xception进行训练在Xception上表现最好，得到了可观的数据。</p>
<h1 id="2stk添加卫星保存场景">2.STK添加卫星保存场景</h1>
]]></content>
    </entry>
</feed>